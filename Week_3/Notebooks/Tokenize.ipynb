{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# English Sentences\n",
    "sentence_1 = \"Hello there! How are you doing today? I hope everything is going well; the weather is nice, isn't it?\"\n",
    "sentence_2 = \"She said, 'Iâ€™ll be there by 5:00 PM'; however, she arrived at 6:30 instead. Was she late, or was I early?\"\n",
    "sentence_3 = \"Despite the warningsâ€”loud and clearâ€”he proceeded with his plan: a risky yet thrilling adventure!\"\n",
    "sentence_4 = \"The report stated: 'Inflation rates have surged by 5% this year.' Can you believe it? It's quite alarming!\"\n",
    "sentence_5 = \"Walking through the dark alley, he hesitated: was that a shadow moving, or just his imagination playing tricks?\"\n",
    "\n",
    "# Arabic Sentences\n",
    "sentence_6 = \"Ù…Ø±Ø­Ø¨Ù‹Ø§! ÙƒÙŠÙ ÙƒØ§Ù† ÙŠÙˆÙ…ÙƒØŸ Ø£ØªÙ…Ù†Ù‰ Ø£Ù† ÙŠÙƒÙˆÙ† ÙƒÙ„ Ø´ÙŠØ¡ Ø¹Ù„Ù‰ Ù…Ø§ ÙŠØ±Ø§Ù…Ø› Ø§Ù„Ø·Ù‚Ø³ Ø±Ø§Ø¦Ø¹ØŒ Ø£Ù„ÙŠØ³ ÙƒØ°Ù„ÙƒØŸ\"\n",
    "sentence_7 = \"Ù‚Ø§Ù„Øª: 'Ø³Ø£ØµÙ„ Ø§Ù„Ø³Ø§Ø¹Ø© Ù¥:Ù Ù  Ù…Ø³Ø§Ø¡Ù‹'Ø› Ù„ÙƒÙ†Ù‡Ø§ ÙˆØµÙ„Øª Ø¹Ù†Ø¯ Ø§Ù„Ø³Ø§Ø¹Ø© Ù¦:Ù£Ù  Ø¨Ø¯Ù„Ù‹Ø§ Ù…Ù† Ø°Ù„Ùƒ! Ù‡Ù„ ØªØ£Ø®Ø±ØªØŒ Ø£Ù… Ø£Ù†Ù†ÙŠ ÙƒÙ†Øª Ù…Ø¨ÙƒØ±Ù‹Ø§ØŸ\"\n",
    "sentence_8 = \"Ø¹Ù„Ù‰ Ø§Ù„Ø±ØºÙ… Ù…Ù† Ø§Ù„ØªØ­Ø°ÙŠØ±Ø§Øªâ€”Ø§Ù„ÙˆØ§Ø¶Ø­Ø© ÙˆØ§Ù„ØµØ§Ø±Ù…Ø©â€”ÙˆØ§ØµÙ„ Ø®Ø·ØªÙ‡: Ù…ØºØ§Ù…Ø±Ø© Ø®Ø·ÙŠØ±Ø© Ù„ÙƒÙ†Ù‡Ø§ Ù…Ø«ÙŠØ±Ø©!\"\n",
    "sentence_9 = \"Ø°ÙƒØ±Øª Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ±: 'Ø§Ø±ØªÙØ¹ Ù…Ø¹Ø¯Ù„ Ø§Ù„ØªØ¶Ø®Ù… Ø¨Ù†Ø³Ø¨Ø© Ù¥Ùª Ù‡Ø°Ø§ Ø§Ù„Ø¹Ø§Ù…'ØŒ Ù‡Ù„ ÙŠÙ…ÙƒÙ†Ùƒ ØªØµØ¯ÙŠÙ‚ Ø°Ù„ÙƒØŸ Ø¥Ù†Ù‡ Ø£Ù…Ø± Ù…Ù‚Ù„Ù‚ Ù„Ù„ØºØ§ÙŠØ©!\"\n",
    "sentence_10 = \"Ø¨ÙŠÙ†Ù…Ø§ ÙƒØ§Ù† ÙŠØ³ÙŠØ± ÙÙŠ Ø§Ù„Ø²Ù‚Ø§Ù‚ Ø§Ù„Ù…Ø¸Ù„Ù…ØŒ ØªØ±Ø¯Ø¯: Ù‡Ù„ ÙƒØ§Ù† Ø°Ù„Ùƒ Ø¸Ù„Ù‹Ø§ ÙŠØªØ­Ø±ÙƒØŒ Ø£Ù… Ø£Ù† Ø®ÙŠØ§Ù„Ù‡ ÙŠØ®Ø¯Ø¹Ù‡ØŸ\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokens\n",
    "\n",
    "### Introduction\n",
    "Tokens are the fundamental units of text processing in Natural Language Processing (NLP). Tokenization is the process of breaking down a sentence into smaller meaningful units, such as words, punctuation marks, or subwords. This process helps in analyzing text more effectively.\n",
    "\n",
    "### Tokens Only Read\n",
    "\n",
    "### Conclusion\n",
    "Tokenization is a crucial preprocessing step in NLP that transforms raw text into structured data. It enables better text analysis and is essential for various NLP applications. Simply put, **tokens help break a sentence into smaller parts that can be processed efficiently.** ğŸš€\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.language import Language\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\aakam\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Shape</th>\n",
       "      <th>Shape_</th>\n",
       "      <th>Is_Stopword</th>\n",
       "      <th>Is_Alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hello</td>\n",
       "      <td>16072095006890171862</td>\n",
       "      <td>Xxxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>there</td>\n",
       "      <td>13110060611322374290</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>!</td>\n",
       "      <td>17494803046312582752</td>\n",
       "      <td>!</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How</td>\n",
       "      <td>18200729499220207786</td>\n",
       "      <td>Xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>are</td>\n",
       "      <td>4088098365541558500</td>\n",
       "      <td>xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>you</td>\n",
       "      <td>4088098365541558500</td>\n",
       "      <td>xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>doing</td>\n",
       "      <td>13110060611322374290</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>today</td>\n",
       "      <td>13110060611322374290</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>?</td>\n",
       "      <td>8205403955989537350</td>\n",
       "      <td>?</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I</td>\n",
       "      <td>101</td>\n",
       "      <td>X</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Text                 Shape Shape_  Is_Stopword  Is_Alpha\n",
       "0  Hello  16072095006890171862  Xxxxx         True     False\n",
       "1  there  13110060611322374290   xxxx         True      True\n",
       "2      !  17494803046312582752      !        False     False\n",
       "3    How  18200729499220207786    Xxx         True      True\n",
       "4    are   4088098365541558500    xxx         True      True\n",
       "5    you   4088098365541558500    xxx         True      True\n",
       "6  doing  13110060611322374290   xxxx         True      True\n",
       "7  today  13110060611322374290   xxxx         True     False\n",
       "8      ?   8205403955989537350      ?        False     False\n",
       "9      I                   101      X         True      True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_1 = nlp(sentence_1)\n",
    "data = [[token.text, token.shape, token.shape_, token.is_alpha, token.is_stop] for token in doc_1]\n",
    "df = pd.DataFrame(data, columns=[\"Text\", \"Shape\", \"Shape_\", \"Is_Stopword\", \"Is_Alpha\"])\n",
    "df.iloc[:10, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>report</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'Inflation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>have</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>surged</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>by</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   token_name\n",
       "0         The\n",
       "1      report\n",
       "2      stated\n",
       "3           :\n",
       "4  'Inflation\n",
       "5       rates\n",
       "6        have\n",
       "7      surged\n",
       "8          by\n",
       "9           5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = word_tokenize(sentence_4)\n",
    "df = pd.DataFrame([token for token in tokens] , columns=[\"token_name\"])\n",
    "df.iloc[:10, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arabic Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Shape</th>\n",
       "      <th>Shape_</th>\n",
       "      <th>Is_Stopword</th>\n",
       "      <th>Is_Alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ù‚Ø§Ù„Øª</td>\n",
       "      <td>13110060611322374290</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>:</td>\n",
       "      <td>11532473245541075862</td>\n",
       "      <td>:</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'</td>\n",
       "      <td>11221368173670222813</td>\n",
       "      <td>'</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ø³Ø£ØµÙ„</td>\n",
       "      <td>13110060611322374290</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ø§Ù„Ø³Ø§Ø¹Ø©</td>\n",
       "      <td>13110060611322374290</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ù¥:Ù Ù </td>\n",
       "      <td>15844590918081457170</td>\n",
       "      <td>d:dd</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ù…Ø³Ø§Ø¡Ù‹</td>\n",
       "      <td>16651002033579018983</td>\n",
       "      <td>xxxxÙ‹</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>'</td>\n",
       "      <td>11221368173670222813</td>\n",
       "      <td>'</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ø›</td>\n",
       "      <td>9495602132000391274</td>\n",
       "      <td>Ø›</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ù„ÙƒÙ†Ù‡Ø§</td>\n",
       "      <td>13110060611322374290</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Text                 Shape Shape_  Is_Stopword  Is_Alpha\n",
       "0    Ù‚Ø§Ù„Øª  13110060611322374290   xxxx         True     False\n",
       "1       :  11532473245541075862      :        False     False\n",
       "2       '  11221368173670222813      '        False     False\n",
       "3    Ø³Ø£ØµÙ„  13110060611322374290   xxxx         True     False\n",
       "4  Ø§Ù„Ø³Ø§Ø¹Ø©  13110060611322374290   xxxx         True     False\n",
       "5    Ù¥:Ù Ù   15844590918081457170   d:dd        False     False\n",
       "6   Ù…Ø³Ø§Ø¡Ù‹  16651002033579018983  xxxxÙ‹        False     False\n",
       "7       '  11221368173670222813      '        False     False\n",
       "8       Ø›   9495602132000391274      Ø›        False     False\n",
       "9   Ù„ÙƒÙ†Ù‡Ø§  13110060611322374290   xxxx         True     False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_1 = nlp(sentence_7)\n",
    "data = [[token.text, token.shape, token.shape_, token.is_alpha, token.is_stop] for token in doc_1]\n",
    "df = pd.DataFrame(data, columns=[\"Text\", \"Shape\", \"Shape_\", \"Is_Stopword\", \"Is_Alpha\"])\n",
    "df.iloc[:10, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ø¨ÙŠÙ†Ù…Ø§</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ÙƒØ§Ù†</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ÙŠØ³ÙŠØ±</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ÙÙŠ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ø§Ù„Ø²Ù‚Ø§Ù‚</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ø§Ù„Ù…Ø¸Ù„Ù…ØŒ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ØªØ±Ø¯Ø¯</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ù‡Ù„</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ÙƒØ§Ù†</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  token_name\n",
       "0      Ø¨ÙŠÙ†Ù…Ø§\n",
       "1        ÙƒØ§Ù†\n",
       "2       ÙŠØ³ÙŠØ±\n",
       "3         ÙÙŠ\n",
       "4     Ø§Ù„Ø²Ù‚Ø§Ù‚\n",
       "5    Ø§Ù„Ù…Ø¸Ù„Ù…ØŒ\n",
       "6       ØªØ±Ø¯Ø¯\n",
       "7          :\n",
       "8         Ù‡Ù„\n",
       "9        ÙƒØ§Ù†"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = word_tokenize(sentence_10)\n",
    "df = pd.DataFrame([token for token in tokens] , columns=[\"token_name\"])\n",
    "df.iloc[:10, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'Language' has no attribute 'Component'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;129m@Language\u001b[39m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mComponent\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_boundries\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mset_custom_boundries\u001b[39m(doc):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m doc[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m token \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: type object 'Language' has no attribute 'Component'"
     ]
    }
   ],
   "source": [
    "\n",
    "@Language.component(\"set_boundaries\")\n",
    "def set_custom_boundaries(doc):\n",
    "    for token in doc[:-1]:\n",
    "        if token.text == \";\":\n",
    "            doc[token.i + 1].is_sent_start = True  \n",
    "    return doc\n",
    "\n",
    "nlp.add_pipe(\"set_boundaries\", before=\"parser\")  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
