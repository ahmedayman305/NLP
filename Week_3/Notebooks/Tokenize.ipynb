{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# English Sentences\n",
    "sentence_1 = \"Hello there! How are you doing today? I hope everything is going well; the weather is nice, isn't it?\"\n",
    "sentence_2 = \"She said, 'I’ll be there by 5:00 PM'; however, she arrived at 6:30 instead. Was she late, or was I early?\"\n",
    "sentence_3 = \"Despite the warnings—loud and clear—he proceeded with his plan: a risky yet thrilling adventure!\"\n",
    "sentence_4 = \"The report stated: 'Inflation rates have surged by 5% this year.' Can you believe it? It's quite alarming!\"\n",
    "sentence_5 = \"Walking through the dark alley, he hesitated: was that a shadow moving, or just his imagination playing tricks?\"\n",
    "\n",
    "# Arabic Sentences\n",
    "sentence_6 = \"مرحبًا! كيف كان يومك؟ أتمنى أن يكون كل شيء على ما يرام؛ الطقس رائع، أليس كذلك؟\"\n",
    "sentence_7 = \"قالت: 'سأصل الساعة ٥:٠٠ مساءً'؛ لكنها وصلت عند الساعة ٦:٣٠ بدلًا من ذلك! هل تأخرت، أم أنني كنت مبكرًا؟\"\n",
    "sentence_8 = \"على الرغم من التحذيرات—الواضحة والصارمة—واصل خطته: مغامرة خطيرة لكنها مثيرة!\"\n",
    "sentence_9 = \"ذكرت التقارير: 'ارتفع معدل التضخم بنسبة ٥٪ هذا العام'، هل يمكنك تصديق ذلك؟ إنه أمر مقلق للغاية!\"\n",
    "sentence_10 = \"بينما كان يسير في الزقاق المظلم، تردد: هل كان ذلك ظلًا يتحرك، أم أن خياله يخدعه؟\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokens\n",
    "\n",
    "### Introduction\n",
    "Tokens are the fundamental units of text processing in Natural Language Processing (NLP). Tokenization is the process of breaking down a sentence into smaller meaningful units, such as words, punctuation marks, or subwords. This process helps in analyzing text more effectively.\n",
    "\n",
    "### Tokens Only Read\n",
    "\n",
    "### Conclusion\n",
    "Tokenization is a crucial preprocessing step in NLP that transforms raw text into structured data. It enables better text analysis and is essential for various NLP applications. Simply put, **tokens help break a sentence into smaller parts that can be processed efficiently.** 🚀\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.language import Language\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\aakam\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Shape</th>\n",
       "      <th>Shape_</th>\n",
       "      <th>Is_Stopword</th>\n",
       "      <th>Is_Alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hello</td>\n",
       "      <td>16072095006890171862</td>\n",
       "      <td>Xxxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>there</td>\n",
       "      <td>13110060611322374290</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>!</td>\n",
       "      <td>17494803046312582752</td>\n",
       "      <td>!</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How</td>\n",
       "      <td>18200729499220207786</td>\n",
       "      <td>Xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>are</td>\n",
       "      <td>4088098365541558500</td>\n",
       "      <td>xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>you</td>\n",
       "      <td>4088098365541558500</td>\n",
       "      <td>xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>doing</td>\n",
       "      <td>13110060611322374290</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>today</td>\n",
       "      <td>13110060611322374290</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>?</td>\n",
       "      <td>8205403955989537350</td>\n",
       "      <td>?</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I</td>\n",
       "      <td>101</td>\n",
       "      <td>X</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Text                 Shape Shape_  Is_Stopword  Is_Alpha\n",
       "0  Hello  16072095006890171862  Xxxxx         True     False\n",
       "1  there  13110060611322374290   xxxx         True      True\n",
       "2      !  17494803046312582752      !        False     False\n",
       "3    How  18200729499220207786    Xxx         True      True\n",
       "4    are   4088098365541558500    xxx         True      True\n",
       "5    you   4088098365541558500    xxx         True      True\n",
       "6  doing  13110060611322374290   xxxx         True      True\n",
       "7  today  13110060611322374290   xxxx         True     False\n",
       "8      ?   8205403955989537350      ?        False     False\n",
       "9      I                   101      X         True      True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_1 = nlp(sentence_1)\n",
    "data = [[token.text, token.shape, token.shape_, token.is_alpha, token.is_stop] for token in doc_1]\n",
    "df = pd.DataFrame(data, columns=[\"Text\", \"Shape\", \"Shape_\", \"Is_Stopword\", \"Is_Alpha\"])\n",
    "df.iloc[:10, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>report</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'Inflation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>have</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>surged</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>by</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   token_name\n",
       "0         The\n",
       "1      report\n",
       "2      stated\n",
       "3           :\n",
       "4  'Inflation\n",
       "5       rates\n",
       "6        have\n",
       "7      surged\n",
       "8          by\n",
       "9           5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = word_tokenize(sentence_4)\n",
    "df = pd.DataFrame([token for token in tokens] , columns=[\"token_name\"])\n",
    "df.iloc[:10, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arabic Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Shape</th>\n",
       "      <th>Shape_</th>\n",
       "      <th>Is_Stopword</th>\n",
       "      <th>Is_Alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>قالت</td>\n",
       "      <td>13110060611322374290</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>:</td>\n",
       "      <td>11532473245541075862</td>\n",
       "      <td>:</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'</td>\n",
       "      <td>11221368173670222813</td>\n",
       "      <td>'</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>سأصل</td>\n",
       "      <td>13110060611322374290</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>الساعة</td>\n",
       "      <td>13110060611322374290</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>٥:٠٠</td>\n",
       "      <td>15844590918081457170</td>\n",
       "      <td>d:dd</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>مساءً</td>\n",
       "      <td>16651002033579018983</td>\n",
       "      <td>xxxxً</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>'</td>\n",
       "      <td>11221368173670222813</td>\n",
       "      <td>'</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>؛</td>\n",
       "      <td>9495602132000391274</td>\n",
       "      <td>؛</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>لكنها</td>\n",
       "      <td>13110060611322374290</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Text                 Shape Shape_  Is_Stopword  Is_Alpha\n",
       "0    قالت  13110060611322374290   xxxx         True     False\n",
       "1       :  11532473245541075862      :        False     False\n",
       "2       '  11221368173670222813      '        False     False\n",
       "3    سأصل  13110060611322374290   xxxx         True     False\n",
       "4  الساعة  13110060611322374290   xxxx         True     False\n",
       "5    ٥:٠٠  15844590918081457170   d:dd        False     False\n",
       "6   مساءً  16651002033579018983  xxxxً        False     False\n",
       "7       '  11221368173670222813      '        False     False\n",
       "8       ؛   9495602132000391274      ؛        False     False\n",
       "9   لكنها  13110060611322374290   xxxx         True     False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_1 = nlp(sentence_7)\n",
    "data = [[token.text, token.shape, token.shape_, token.is_alpha, token.is_stop] for token in doc_1]\n",
    "df = pd.DataFrame(data, columns=[\"Text\", \"Shape\", \"Shape_\", \"Is_Stopword\", \"Is_Alpha\"])\n",
    "df.iloc[:10, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>بينما</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>كان</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>يسير</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>في</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>الزقاق</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>المظلم،</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>تردد</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>هل</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>كان</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  token_name\n",
       "0      بينما\n",
       "1        كان\n",
       "2       يسير\n",
       "3         في\n",
       "4     الزقاق\n",
       "5    المظلم،\n",
       "6       تردد\n",
       "7          :\n",
       "8         هل\n",
       "9        كان"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = word_tokenize(sentence_10)\n",
    "df = pd.DataFrame([token for token in tokens] , columns=[\"token_name\"])\n",
    "df.iloc[:10, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'Language' has no attribute 'Component'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;129m@Language\u001b[39m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mComponent\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_boundries\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mset_custom_boundries\u001b[39m(doc):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m doc[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m token \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: type object 'Language' has no attribute 'Component'"
     ]
    }
   ],
   "source": [
    "\n",
    "@Language.component(\"set_boundaries\")\n",
    "def set_custom_boundaries(doc):\n",
    "    for token in doc[:-1]:\n",
    "        if token.text == \";\":\n",
    "            doc[token.i + 1].is_sent_start = True  \n",
    "    return doc\n",
    "\n",
    "nlp.add_pipe(\"set_boundaries\", before=\"parser\")  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
